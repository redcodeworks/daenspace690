spark {
    logLevel = "ERROR"
    appName = "DaenSpace690"
}


input-data {
    url = "s3a://daenspace690/resources/airlineSops.csv"
    language = "en"
    document = "text"
    label = "label"
    format = "csv"
    train-split = 0.9
}


pipeline {
    name = "bert"
    lemmatizerModel = "lemma_antbnc"

    # choose from "pipeline-only", "cross-validate", or "train-validate"
    # pipeline-only: Runs the train job once with no parameter tuning or cross-validation.
    # cross-validate: Cross-validate and tune parameters on each pass.
    # train-validate: tune parameters once, then cross-validate reusing these parameters.
    mode = "pipeline-only"

    save-fitted = false
    save-fitted-loc = "s3a://daenspace690/model-artifacts/alternative/"

    save-predictions = false
    save-predictions-loc = "s3a://daenspace690/statistics/predictions/"
}

use {
    model = "tfhub_use"
}

glove {
    model = "glove_100d"
    pooling = "AVERAGE"
}

bert {
    model = "bert_base_cased"
    pooling = "AVERAGE"
}

elmo {
    model = "elmo"
    pooling = "AVERAGE"
}